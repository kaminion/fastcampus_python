{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 평가지표 작성해보기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MEDV'] = data['target'] # 주택의 중앙값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전에 사용했던 데이터들\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('MEDV', 1), df['MEDV']) # X 데이터와 Y데이터 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([3, 4, 5])\n",
    "actual = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mse(pred, actual):\n",
    "    return ((pred - actual) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mae(pred, actual):\n",
    "    return np.abs(pred - actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rmse(pred, actual):\n",
    "    return np.sqrt(my_mse(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "my_mse(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "my_mae(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "my_rmse(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = np.array([3, 4, 5])\n",
    "actual = np.array([1, 2, 3])"
   ]
  },
  {
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.0, 2.0)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "my_mae(pred, actual), mean_absolute_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4.0, 4.0)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "my_mse(pred, actual), mean_squared_error(pred, actual)"
   ]
  },
  {
   "source": [
    "모델별 성능 확인을 위한 함수\n",
    "\n",
    "아래는 sklearn 사용을 사용하여 평가지표 작성\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = []\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'khak!', 'orchid', 'sandybrown', 'greenyellow', 'dodgerblue', 'deepskyblue',\n",
    "'deeppink', 'crimson', 'salmon', 'rosybrown',' firebrick', 'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate', 'gold', 'arkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', 'peru',\n",
    "'midhighblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(name_, pred, actual):\n",
    "    df = pd.DataFrame({'prediction': pred, 'actual': y_test})\n",
    "    df = df.sort_values(by='actual').reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.scatter(df.index, df['prediction'], marker=x, color='r')\n",
    "    plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')\n",
    "    plt.title(name_, fontsize=15)\n",
    "    plt.legend(['prediction', 'actual'], fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_eval(name_, pred, actual):\n",
    "    global my_predictions\n",
    "    global colors\n",
    "\n",
    "    plot_predictions(name_, pred, actual)\n",
    "\n",
    "    mse = mean_squared_error(pred, actual)\n",
    "    my_prediction[name_] = mse\n",
    "\n",
    "    y_value = sorted(my_prediction.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    df = pd.DataFrame(y_value, columns=['model', 'mse'])\n",
    "    print(df)\n",
    "    min_ = df['mse'].min() - 10\n",
    "    max_ = df['mse'].max() + 10\n",
    "\n",
    "    length = len(df)\n",
    "\n",
    "    plt.figure(figsize=(10, length))\n",
    "\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['mse'])\n",
    "\n",
    "    for i, v in enumerate(df['mse']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "\n",
    "    plt.title('MSE Error', fontsize=18)\n",
    "    plt.xlim(min_, max_)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_model(name_):\n",
    "    global my_predictions\n",
    "    try:"
   ]
  }
 ]
}